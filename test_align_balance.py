import torch

inputs = torch.tensor([[  0.3560,  -8.6328,  -0.6597,  -5.0742,   9.7266,   6.6836,   1.1309,
          -1.0488,  -6.6602,   4.5781],
        [  5.1836, -14.0078,   6.6445,  -5.2070,  14.9531,   2.5000,   2.7422,
          -2.1777, -10.5312,   0.7002],
        [  7.9648, -13.4219,   3.0938,  -7.0391,  10.3906,   1.9365,   1.0234,
          -1.1055,  -5.6133,   3.1543],
        [  2.3516, -12.0078,   4.1133,  -6.5000,   9.1484,   2.5742,   7.5430,
          -0.6958,  -8.4609,   2.5801],
        [  1.9062, -12.6953,   5.7305,  -3.0723,  13.1406,   1.1484,   3.3242,
          -0.6899,  -7.2852,  -0.9336],
        [  4.2031,  -9.9531,   2.4473,  -7.8203,  13.4141,  -3.0742,   2.4375,
          -0.6680,  -5.2344,   4.6758],
        [  4.0898, -10.3828,   2.8242,  -7.5117,  12.5156,   3.3770,   2.0781,
          -2.2227,  -7.4766,   2.7734],
        [  5.9414, -13.3906,   2.2500,  -7.2227,  11.4688,  -1.6426,   2.9512,
           0.6978,  -7.0820,   6.4570]]).cuda(1)
inputs2 = torch.tensor([[  0.3560, -8.6328, -5.0742, -0.6597,  9.7266,   6.6836,   1.1309,
          -1.0488,  -6.6602,   4.5781],
        [  5.1836, -14.0078,   6.6445,    14.9531,  -5.2070, 2.5000,   2.7422,
          -2.1777, -10.5312,   0.7002],
        [  7.9648, -13.4219,   3.0938,  -7.0391,  10.3906,   1.9365,   1.0234,
          -1.1055,  -5.6133,   3.1543],
        [  2.3516, -12.0078,   4.1133,  -6.5000,   9.1484,   2.5742,   7.5430,
          -0.6958,  -8.4609,   2.5801],
        [  1.9062, -12.6953,   5.7305,  -3.0723,  13.1406,   1.1484,   3.3242,
          -0.6899,  -7.2852,  -0.9336],
        [  4.2031,  -9.9531,   2.4473,  -7.8203,  13.4141,  -3.0742,   2.4375,
          -0.6680,  -5.2344,   4.6758],
        [  4.0898, -10.3828,   2.8242,  -7.5117,  12.5156,   3.3770,   2.0781,
          -2.2227,  -7.4766,   2.7734],
        [  5.9414, -13.3906,   2.2500,  -7.2227,  11.4688,  -1.6426,   2.9512,
           0.6978,  -7.0820,   6.4570]]).cuda(1)

def lossAB(inputs):
    pyx = torch.nn.functional.softmax(inputs, dim=1)
    log_pyx = torch.nn.functional.log_softmax(inputs, dim=1)
    py = pyx.mean(0)
    loss_align = -(pyx * log_pyx).sum(1).mean()
    loss_balance = (py * torch.log2(py)).sum()
    return loss_align, loss_balance

print(lossAB(inputs))
print(lossAB(inputs2))
